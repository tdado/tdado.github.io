<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-03T20:22:08+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Thirza Dado</title><subtitle>An amazing website.</subtitle><author><name>Thirza Dado</name></author><entry><title type="html">Neural decoding of uncanniness</title><link href="http://localhost:4000/uncanny/" rel="alternate" type="text/html" title="Neural decoding of uncanniness" /><published>2022-09-29T00:00:00+02:00</published><updated>2022-09-29T00:00:00+02:00</updated><id>http://localhost:4000/uncanny</id><content type="html" xml:base="http://localhost:4000/uncanny/"><![CDATA[<p>2022, 29 September</p>

<h3 id="an-uncanny-valley-or-cliff">An uncanny valley or¬†-cliff?</h3>

<p><em>Written by Thirza Dado &amp; Umut G√º√ßl√º.</em></p>

<p><img src="/assets/images/synth3.png" alt="Top" />
<em>The uncanny cliff hypothesizes that artificial figures remain either on the cliff (i.e., perceived as human-like) or they fall from the cliff (i.e., perceived as fake with disturbing feelings of eeriness and unease).</em></p>

<p>Generative Adversarial Networks (GANs) are powerful generative models trained to synthesize (‚Äú<em>fake</em>‚Äù) data that seem indistinguishable from ‚Äú<em>real</em>‚Äù data. <a href="https://www.nature.com/articles/s41598-021-03938-w">A recent study</a> demonstrated with an experiment how GANs can be used to reconstruct literal pictures of what volunteers in the brain scanner were seeing by neural decoding of their brain recordings. Concretely, these volunteers were looking at <strong>pictures of faces of people</strong>; faces that <a href="https://thispersondoesnotexist.com/">do not really exist</a> but are instead synthesized by a ü§ñ<a href="https://github.com/tkarras/progressive_growing_of_gans">Progressively Grown GAN (PGGAN)</a> for faces.</p>

<p>The goal of neural decoding is to discover what information (about a stimulus) is present in the brain. That said, any property of a stimulus could potentially be decoded from the brain.</p>

<p><img src="/assets/images/grad2.png" alt="Gradient" />
<em>A selection of faces from the used dataset illustrates that some faces look more natural or real and some faces look more fake. We call this property ‚Äúsyntheticity‚Äù.</em></p>

<p>Although the presented faces in the experiment look hyperreal to human observers in general (but are all fake and do not exist), close inspection of the used face stimuli revealed that some faces look less real than others, resulting in disturbing feelings of eeriness and unease. That is, these data have a property of ‚Äúsyntheticity‚Äù that denotes how real or fake a face looks.</p>

<p>The <a href="https://web.ics.purdue.edu/~drkelly/MoriTheUncannyValley1970.pdf">uncanny valley theory</a> hypothesizes that the affinity response of a human observer towards an artificial figure becomes more and more positive when it looks more and more human-like but up to a certain point where it abruptly switches from empathy to revulsion. Alternatively, it has been proposed that the valley is more like an <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4415111&amp;casa_token=VDO-WB9Ov5EAAAAA:JQY0Zg4MJUUOpjTcuTpoXxaGc51VdSXqjboQhzgD-3yijNYFhg2F69jr198-GiK_r8XRZFKKknSo&amp;tag=1">uncanny cliff</a>:</p>

<blockquote>
  <p><em>‚ÄúWe are not certain if this section [of the uncanny valley between the deepest dip and the human level] actually exists thereby prompting us to suggest that the uncanny valley should be considered more of a cliff than a valley, where robots strongly resembling humans could either fall from the cliff or they could be perceived as being human.‚Äù</em></p>

  <p><cite>Bartneck, C., Kanda, T., Ishiguro, H., &amp; Hagita, N. (2007)</cite></p>
</blockquote>

<p>Here, we will decode syntheticity from neural data and see whether the results indicate a gradient or a cliff!</p>

<p><img src="/assets/images/exp.png" alt="Experiment" />
<em>Behavioral experiment to sort faces on syntheticity.</em></p>

<h5 id="behavioral-data">Behavioral data</h5>

<p>To quantify the behavioral phenomenon of perceived syntheticity, we can do a behavioral experiment where a volunteer attributes <em>syntheticity scores</em> to all the faces. Concretely, the volunteer (i.e., <em>me</em>, I volunteered) sees two face images at a time and is asked ‚Äúwhich face looks more real‚Äù and, if this question was too difficult to answer, ‚Äúwhich face do you like better‚Äù. As such, the faces get scored on syntheticity and we can sort them from real- to fake-looking.</p>

<p>To be more efficient than presenting combinations of face pairs with a worst-case performance of O(n¬≤) with n=1086, we can go and implement the divide and conquer <a href="https://www.geeksforgeeks.org/merge-sort/">merge sort</a> algorithm that iteratively merges smaller lists of sorted images until one big sorted list of fake-to-real-looking faces remains. This algorithm sorts each face in relation to other faces but <em>not all the other faces</em> because we can already infer knowledge from earlier decisions, resulting in a worst-case bound of O(n log n) (i.e., it still took me three days to make 10136 comparisonsüò¨). The experiment was implemented in <a href="https://unity.com/">Unity</a> and C#.</p>

<p>You can find the result files here: <em>ridx</em> contains the initial (unsorted) index order that determined which pair of faces would be presented to the screen and <em>sidx</em> is the index list sorted on syntheticity by the volunteer. That is, we sort the original <em>ridx</em> by the ‚Äúsorted‚Äù <em>sidx</em>. In the last for-loop in the code snippet below, we then sort again from 0 to 1086 (fake- to real-looking).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s">"sidx_T_7_10136.txt"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">sidx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">f</span> <span class="p">])</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s">"ridx_T_7_10136.txt"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">ridx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span> <span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">f</span> <span class="p">])[:</span><span class="nb">len</span><span class="p">(</span><span class="n">sidx</span><span class="p">)]</span>
<span class="nb">sorted</span> <span class="o">=</span> <span class="n">ridx</span><span class="p">[</span><span class="n">sidx</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1086</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1086</span><span class="p">):</span>
    <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="nb">sorted</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<h5 id="neural-data">Neural data</h5>
<p>We use the hyper dataset of fMRI measurements to PGGAN-generated face stimuli (<a href="https://openneuro.org/datasets/ds004280/versions/1.0.0">whole dataset</a>). In this blog post, we use the same 4096-voxel selection as the original hyper study which can be found <a href="https://drive.google.com/drive/u/1/folders/1OW0cfnoP8_tZBGWLbpiPPX81QH9pusjv">here</a> but it would also be interesting to have a look at whole-brain or different brain areas. Let‚Äôs hyperalign and average the brain data of the two participants (just like we did in a <a href="https://medium.com/neural-coding-lab/neural-decoding-w-synthesized-reality-5eeb476f399">previous blog post</a>). Alternatively, you can also just pick the brain responses of either subject 1 or 2.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">swig</span>
<span class="err">!</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">pymvpa2</span>
<span class="kn">import</span> <span class="nn">mvpa2.datasets</span>
<span class="kn">import</span> <span class="nn">mvpa2.algorithms.hyperalignment</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="k">def</span> <span class="nf">hyperalignment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">mvpa2</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
    <span class="n">hyperalignment</span> <span class="o">=</span> <span class="n">mvpa2</span><span class="p">.</span><span class="n">algorithms</span><span class="p">.</span><span class="n">hyperalignment</span><span class="p">.</span><span class="n">Hyperalignment</span><span class="p">()(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyperalignment</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">forward</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">j</span><span class="p">]).</span><span class="n">samples</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
<span class="n">path</span> <span class="o">=</span> <span class="s">"/yourpath/"</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s">"data_1.dat"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">X_tr1</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">X_te1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s">"data_2.dat"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">X_tr2</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">X_te2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te1</span> <span class="o">+</span> <span class="n">X_tr1</span><span class="p">)</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te2</span> <span class="o">+</span> <span class="n">X_tr2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">hyperalignment</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">X_2</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="neural-decoding">Neural decoding</h5>
<p>We do  a linear mapping from brain responses to syntheticity scores. The original dataset order (test + train) is permuted to ensure various degrees of syntheticity because the quality in the original test set (36 faces) was quite good. The syntheticity scores in the test set would otherwise all be more or less similar (i.e., very real-looking). We use a 90:10 split where 90% of the data is used as the training set and the remaining 10% is used as the held-out test set to evaluate model performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">permutation</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="mi">1086</span><span class="p">)</span>
<span class="n">_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>
<span class="n">_T</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">permutation</span><span class="p">]</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1086</span> <span class="o">/</span> <span class="mi">100</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">x_te</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">_X</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
<span class="n">x_tr</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">_X</span><span class="p">[</span><span class="n">n</span><span class="p">:])</span>
<span class="n">t_te</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">_T</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
<span class="n">t_tr</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">_T</span><span class="p">[</span><span class="n">n</span><span class="p">:])</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">t_tr</span><span class="p">)</span>
<span class="n">y_te</span> <span class="o">=</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>
</code></pre></div></div>

<h5 id="evaluation">Evaluation</h5>
<p>To evaluate the model performance of our linear decoder, we can look at the correlation between the predicted scores from brain data and the syntheticity scores from the behavioral experiment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span>

<span class="k">def</span> <span class="nf">pearson_correlation_coefficient</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">stats</span><span class="p">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">stats</span><span class="p">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">y</span><span class="p">))).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">t</span><span class="p">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">r</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))),</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span>

<span class="n">r</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">pearson_correlation_coefficient</span><span class="p">(</span><span class="n">y_te</span><span class="p">,</span> <span class="n">t_te</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">r</span><span class="p">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">p</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</code></pre></div></div>

<p>This results in r=0.4298, p=3.46e-06, meaning that we can indeed predict continuous syntheticity scores from the fMRI recordings from the hyper experiment. This means that the neural representations of the perceived faces contain continuous- rather than binary information on syntheticity. Otherwise, if the encoded information would have been binary (either real- or fake-looking), it would not have been possible to decode these continuous values from the brain. <strong>In conclusion, our result supports the uncanny valley theory rather than the uncanny cliff.</strong></p>

<p>It would be cool to make comparisons with other metrics such as feature maps and/or (classification) scores of discriminator networks. Further, we could also use a searchlight to identify where and with what magnitude syntheticity is encoded in the brain.</p>

<p>That‚Äôs all.</p>]]></content><author><name>Thirza Dado</name></author><summary type="html"><![CDATA[2022, 29 September]]></summary></entry><entry><title type="html">Neural decoding w/ synthesized reality</title><link href="http://localhost:4000/hyper/" rel="alternate" type="text/html" title="Neural decoding w/ synthesized reality" /><published>2022-01-22T00:00:00+01:00</published><updated>2022-01-22T00:00:00+01:00</updated><id>http://localhost:4000/hyper</id><content type="html" xml:base="http://localhost:4000/hyper/"><![CDATA[<p>2022, 22 January</p>

<h3 id="hyperrealistic-reconstruction-of-perceived-faces-from-fmri-data">HYperrealistic reconstruction of PERceived faces from fMRI data</h3>

<p><img src="/assets/images/top.png" alt="Top" />
<em>Stimuli (top row) and their reconstructions from brain data (bottom row).</em></p>

<p>Neural decoding seeks to find what information about a perceived external stimulus is present in the corresponding brain response. In particular, the original stimulus can be reconstructed based on brain data alone. This study resulted in the most accurate reconstructions of face perception to date by decoding the brain recordings of two individual participants separately. To get even closer, we repeated this approach with the averaged brain responses.</p>

<p>Here, we show you how we did it.</p>

<h5 id="hyper">HYPER</h5>
<p>In the original paper, two participants in the brain scanner were presented with face stimuli that elicited specific functional responses in their brains. This experiment resulted in a (faces, responses) dataset that taught a decoder to map brain responses to the corresponding faces. This trained decoder could now transform unseen (held-out) brain data back into the perceived stimuli. The model was called HYPER (HYperrealistic reconstruction of PERception).</p>

<p><img src="/assets/images/m1.png" alt="Experiment" />
<em>The face stimulus was presented to the participant in the MRI scanner that recorded the corresponding neural responses. Neural decoding of these responses then reconstructed what the participant was originally seeing.</em></p>

<p>The secret ingredient was the following: the face stimuli were artificially synthesized by the generator network of a progressively grown GAN for faces from randomly sampled latent vectors; the people in the presented images did not really exist. As such, the latents underlying these faces were known (because they were used for generation in the first place) whereas those of real face images can never be directly accessed‚Ää-‚Ääonly approximated which entails information loss. Note that these results are legitimate reconstructions of visual perception regardless of the nature of the stimuli themselves.</p>

<p><img src="/assets/images/m2.png" alt="Pipeline" />
<em>Schematic workflow of HYPER. A latent is fed to the GAN to generate a face image that is presented to a participant in the MRI scanner. From the recorded brain response to this stimulus, we predict a latent that is also fed to the GAN for (re-)generation.</em></p>

<p>The high resemblance indicates a linear relationship between latents and brain recordings. Simply put, latents and brains effectively captured the same defining stimulus features (e.g., age, gender, hair color, pose) so that latents could be predicted as a linear combination of the brain data and fed to the generator for (re-)generation of what was perceived.</p>

<h5 id="hyperalignment-brainremix">Hyperalignment (brain¬†remix)</h5>

<p>The original study trained a separate decoder for each individual participant. To get even closer to the external stimulus, we can capture the shared neural information across participants by applying an additional preprocessing step to the brain data. This step involves aligning and reslicing the functional brain responses with hyperalignment‚Ää-‚Ääa remixing process that iteratively maps brain data of multiple participants to a common functional space. Note that we are working in the functional domain which is about brain function rather than the topography in the anatomical domain. The responses of different brains are now comparable in function and the average brain response per stimulus can be taken to train one general decoder.</p>

<p>All the stimulus-reconstruction pairs in this post result from HYPER with hyperaligned and averaged data.</p>

<p><img src="/assets/images/1.png" alt="Recon1" />
<em>Stimuli (top row) and their reconstructions from brain data (bottom row).</em></p>

<p><img src="/assets/images/2.png" alt="Recon2" />
<em>Stimuli (top row) and their reconstructions from brain data (bottom row).</em></p>

<h3 id="tutorial">Tutorial</h3>
<p>Hyperalignment can be implemented using <a href="http://www.pymvpa.org/">PyMVPA</a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">swig</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">pymvpa2</span>
<span class="kn">import</span> <span class="nn">mvpa2.datasets</span>
<span class="kn">import</span> <span class="nn">mvpa2.algorithms.hyperalignment</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="k">def</span> <span class="nf">hyperalignment</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>    
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>    
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">mvpa2</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span> <span class="k">for</span> <span class="n">x_</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>    
    <span class="n">hyperalignment</span> <span class="o">=</span> <span class="n">mvpa2</span><span class="p">.</span><span class="n">algorithms</span><span class="p">.</span><span class="n">hyperalignment</span><span class="p">.</span><span class="n">Hyperalignment</span><span class="p">()(</span><span class="n">dataset</span><span class="p">)</span>    
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyperalignment</span><span class="p">[</span><span class="n">j</span><span class="p">].</span><span class="n">forward</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">j</span><span class="p">]).</span><span class="n">samples</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))]</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span>
</code></pre></div></div>

<p>Load in the data (publicly accessible in <a href="https://drive.google.com/drive/u/1/folders/1NEblHtlRFvUyD5CA2sqSVfcGlfJBqw_T">Google Drive</a>). The test and training set consist of 36 and 1050 trials of 4096 (flattened) voxel responses, respectively. Concatenate the test and training data before hyperalignment.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"yourpath/data_1.dat"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">X_tr1</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">X_te1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"yourpath/data_2.dat"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">X_tr2</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">X_te2</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">X_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te1</span> <span class="o">+</span> <span class="n">X_tr1</span><span class="p">)</span>
<span class="n">X_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te2</span> <span class="o">+</span> <span class="n">X_tr2</span><span class="p">)</span>
<span class="n">X_hyperaligned</span> <span class="o">=</span> <span class="n">hyperalignment</span><span class="p">(</span><span class="n">X_1</span><span class="p">,</span> <span class="n">X_2</span><span class="p">)</span>
</code></pre></div></div>

<p>Train a neural decoder to predict latents from brain data. This decoder is implemented in MXNet. Let‚Äôs import the required libraries.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">mxnet</span><span class="o">-</span><span class="n">cu101</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="n">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">autograd</span><span class="p">,</span> <span class="n">gluon</span><span class="p">,</span> <span class="n">nd</span><span class="p">,</span> <span class="n">symbol</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon.nn</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">HybridBlock</span><span class="p">,</span>       
    <span class="n">HybridSequential</span><span class="p">,</span> <span class="n">LeakyReLU</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">mxnet.initializer</span> <span class="kn">import</span> <span class="n">Zero</span>
<span class="kn">from</span> <span class="nn">mxnet.io</span> <span class="kn">import</span> <span class="n">NDArrayIter</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
</code></pre></div></div>

<p>Below you can find a MXNet implementation of the PGGAN generator. It takes a 512-dimensional latent and transforms it into a 1024 √ó1024 RGB image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Pixelnorm</span><span class="p">(</span><span class="n">HybridBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">epsilon</span>
    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nd</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">F</span><span class="p">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">eps</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Bias</span><span class="p">(</span><span class="n">HybridBlock</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bias</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"b"</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="n">Zero</span><span class="p">(),</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nd</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">F</span><span class="p">.</span><span class="n">broadcast_add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span>

<span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">HybridSequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Block</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">())</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="n">channels</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">())</span>
    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nd</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">Generator</span><span class="p">(</span><span class="n">HybridSequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Generator</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">())</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8192</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">in_units</span><span class="o">=</span><span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bias</span><span class="p">((</span><span class="mi">512</span><span class="p">,)))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">())</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Pixelnorm</span><span class="p">())</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Block</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">:</span> <span class="n">Union</span><span class="p">(</span><span class="n">nd</span><span class="p">,</span> <span class="n">symbol</span><span class="p">),</span> <span class="n">x</span><span class="p">:</span> <span class="n">nd</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nd</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">Reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="bp">self</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">layer</span> <span class="o">+</span> <span class="mi">7</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p>A dense (decoding) layer then transforms the 4096-dimensional functional responses into 512-dimensional latents. Only train the weights of this layer and keep the generator weights fixed.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">HybridSequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Linear</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="k">with</span> <span class="bp">self</span><span class="p">.</span><span class="n">name_scope</span><span class="p">():</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_out</span><span class="p">,</span> <span class="n">in_units</span><span class="o">=</span><span class="n">n_in</span><span class="p">))</span>
</code></pre></div></div>

<p>Before training, all data have to be transformed to be of type <a href="https://mxnet.apache.org/versions/1.6/api/python/docs/api/ndarray/index.html">NDArray</a> (make sure to also store on GPU if you have access). The weight parameters of the generator (MXNet) can be found on Drive. Note that we are using gradient descent to fit the weights of the dense layer whereas ordinary least squares would yield a similar solution. However, the current setup allows you to experiment and try different things to make more sophisticated models (e.g., predict intermediate layer activations of PGGAN and include this in your loss function).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set parameters.
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">n_lat</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">n_vox</span> <span class="o">=</span> <span class="mi">4096</span>

<span class="c1"># Make dataset to take batches from during training.
</span><span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">NDArrayIter</span><span class="p">({</span> <span class="s">"x"</span><span class="p">:</span> <span class="n">nd</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">},</span> <span class="p">{</span> <span class="s">"t"</span><span class="p">:</span> <span class="n">nd</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="o">*</span><span class="n">t</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="p">},</span> <span class="n">batch_size</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>

<span class="c1"># Latents.
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"yourpath/data_1.dat"</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">T_tr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">T_te</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># Z-score the brain data.
</span><span class="n">X_te</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">X_hyperaligned</span><span class="p">[:</span><span class="mi">36</span><span class="p">])</span>
<span class="n">X_tr</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">X_hyperaligned</span><span class="p">[</span><span class="mi">36</span><span class="p">:])</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">nd</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">T_tr</span><span class="p">),</span> <span class="n">nd</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_tr</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span>  <span class="n">load_dataset</span><span class="p">(</span><span class="n">nd</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">T_te</span><span class="p">),</span> <span class="n">nd</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">36</span><span class="p">)</span>

<span class="c1"># Initialize generator.
</span><span class="n">generator</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">()</span>
<span class="n">generator</span><span class="p">.</span><span class="n">load_parameters</span><span class="p">(</span><span class="s">"yourpath/generator.params"</span><span class="p">)</span>
<span class="n">mean_squared_error</span> <span class="o">=</span> <span class="n">gluon</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="n">L2Loss</span><span class="p">()</span>

<span class="c1"># Initialize linear model.
</span><span class="n">vox_to_lat</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">n_vox</span><span class="p">,</span> <span class="n">n_lat</span><span class="p">)</span>
<span class="n">vox_to_lat</span><span class="p">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">gluon</span><span class="p">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">vox_to_lat</span><span class="p">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s">"Adam"</span><span class="p">,</span> <span class="p">{</span><span class="s">"learning_rate"</span><span class="p">:</span> <span class="mf">0.00001</span><span class="p">,</span> <span class="s">"wd"</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">})</span>

<span class="c1"># Training.
</span><span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">results_tr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">results_te</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">while</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">max_epoch</span><span class="p">:</span>
    <span class="n">train</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">test</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">loss_tr</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_te</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_tr</span> <span class="ow">in</span> <span class="n">train</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">autograd</span><span class="p">.</span><span class="n">record</span><span class="p">():</span>
            <span class="n">lat_Y</span> <span class="o">=</span> <span class="n">vox_to_lat</span><span class="p">(</span><span class="n">batch_tr</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">lat_Y</span><span class="p">,</span> <span class="n">batch_tr</span><span class="p">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">trainer</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">loss_tr</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">mean</span><span class="p">().</span><span class="n">asnumpy</span><span class="p">()</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">batch_te</span> <span class="ow">in</span> <span class="n">test</span><span class="p">:</span>
        <span class="n">lat_Y</span> <span class="o">=</span> <span class="n">vox_to_lat</span><span class="p">(</span><span class="n">batch_te</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">lat_Y</span><span class="p">,</span> <span class="n">batch_te</span><span class="p">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">loss_te</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">mean</span><span class="p">().</span><span class="n">asnumpy</span><span class="p">()</span>
    <span class="n">loss_tr_normalized</span> <span class="o">=</span> <span class="n">loss_tr</span> <span class="o">/</span> <span class="n">count</span>
    <span class="n">results_tr</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_tr_normalized</span><span class="p">)</span>
    <span class="n">results_te</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_te</span><span class="p">)</span>
    <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Epoch %i: %.4f / %.4f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss_tr_normalized</span><span class="p">,</span> <span class="n">loss_te</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">epoch</span><span class="p">),</span> <span class="n">results_tr</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">epoch</span><span class="p">),</span> <span class="n">results_te</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>After training, reconstruct faces from the test set responses. Note that the test data is not used for training (you only computed the test loss per epoch for plotting purposes) such that the model never encountered this brain data before.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Testing and reconstructing
</span><span class="n">lat_Y</span> <span class="o">=</span> <span class="n">vox_to_lat</span><span class="p">(</span><span class="n">nd</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_te</span><span class="p">))</span>
<span class="nb">dir</span> <span class="o">=</span> <span class="s">"yourpath/reconstructions"</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="nb">dir</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="n">mkdir</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">latent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lat_Y</span><span class="p">):</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">latent</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="mi">9</span><span class="p">).</span><span class="n">asnumpy</span><span class="p">()</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">clip</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">rint</span><span class="p">(</span><span class="mf">127.5</span> <span class="o">*</span> <span class="n">face</span> <span class="o">+</span> <span class="mf">127.5</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">255.0</span><span class="p">)</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">face</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"uint8"</span><span class="p">).</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Image</span><span class="p">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">face</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'RGB'</span><span class="p">).</span><span class="n">save</span><span class="p">(</span><span class="nb">dir</span> <span class="o">+</span> <span class="s">"/%d.png"</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
</code></pre></div></div>

<p>In the end, one decoding model was trained on averaged functional neural responses which resulted in face reconstructions spectacularly analogous to the originally perceived faces. This raises the question of how close neural decoding can get to objective reality if we average the brain data of an even larger pool of eyewitnesses.</p>

<p>That‚Äôs all folks!</p>

<p><img src="/assets/images/3.png" alt="Recon3" /></p>

<p><img src="/assets/images/4.png" alt="Recon4" />
<em>Stimuli (top row) and their reconstructions from brain data (bottom row).</em></p>

<p>Dado, T., G√º√ßl√ºt√ºrk, Y., Ambrogioni, L. et al. Hyperrealistic neural decoding for reconstructing faces from fMRI activations via the GAN latent space. Sci Rep 12, 141 (2022). https://doi.org/10.1038/s41598-021-03938-w</p>]]></content><author><name>Thirza Dado</name></author><summary type="html"><![CDATA[2022, 22 January]]></summary></entry></feed>